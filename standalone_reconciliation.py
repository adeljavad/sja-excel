#!/usr/bin/env python3
"""
Standalone Intelligent Reconciliation System
Ø³ÛŒØ³ØªÙ… Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø³ØªÙ‚Ù„

Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚Ù„ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ùˆ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø±Ø§ Ø¨Ù‡ Ø¢Ù† Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ Ù†ØªØ§ÛŒØ¬ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯.

Usage:
    python standalone_reconciliation.py file_a.xlsx file_b.xlsx [output_file.xlsx]
"""

import pandas as pd
import sys
import os
import re
import argparse
from pathlib import Path


class StandaloneReconciliation:
    """Ø³ÛŒØ³ØªÙ… Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø³ØªÙ‚Ù„"""
    
    def __init__(self):
        self.column_mapping = {
            # Persian column names
            'Ø´Ø±Ø­': 'description',
            'Ù…Ø¨Ù„Øº': 'amount',
            'ØªØ§Ø±ÛŒØ®': 'date',
            'Ø´Ù…Ø§Ø±Ù‡ Ø³Ù†Ø¯': 'document_number',
            'Ø´Ù…Ø§Ø±Ù‡ Ø­Ø³Ø§Ø¨': 'account_number',
            'Ù†Ø§Ù… Ø­Ø³Ø§Ø¨': 'account_name',
            
            # English column names
            'description': 'description',
            'amount': 'amount',
            'date': 'date',
            'document_number': 'document_number',
            'account_number': 'account_number',
            'account_name': 'account_name',
            
            # Common variations
            'Ø´Ø±Ø­ Ø¹Ù…Ù„ÛŒØ§Øª': 'description',
            'Ø´Ø±Ø­ ØªØ±Ø§Ú©Ù†Ø´': 'description',
            'Ù…Ø¨Ù„Øº ØªØ±Ø§Ú©Ù†Ø´': 'amount',
            'Ù…Ø¨Ù„Øº Ø¹Ù…Ù„ÛŒØ§Øª': 'amount',
            'ØªØ§Ø±ÛŒØ® ØªØ±Ø§Ú©Ù†Ø´': 'date',
            'ØªØ§Ø±ÛŒØ® Ø¹Ù…Ù„ÛŒØ§Øª': 'date',
        }
    
    def extract_invoice_number(self, description):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ ØµÙˆØ±Øªâ€ŒÙˆØ¶Ø¹ÛŒØª Ø§Ø² Ø´Ø±Ø­"""
        if not description:
            return None
        
        patterns = [
            r'ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª\s*[:Ø›]?\s*(\d+)',
            r'Ø´Ù…Ø§Ø±Ù‡\s*ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª\s*[:Ø›]?\s*(\d+)',
            r'Ø´Ù…Ø§Ø±Ù‡\s*[:Ø›]?\s*(\d+)',
            r'ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª Ø´Ù…Ø§Ø±Ù‡\s*(\d+)',
            r'Ø´.\s*Ùˆ.\s*(\d+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, str(description), re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def extract_check_number(self, description):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ù…Ø§Ø±Ù‡ Ú†Ú© Ø§Ø² Ø´Ø±Ø­"""
        if not description:
            return None
            
        patterns = [
            r'Ú†Ú©\s*Ø´Ù…Ø§Ø±Ù‡\s*(\d+)',
            r'Ø´Ù…Ø§Ø±Ù‡ Ú†Ú©\s*(\d+)',
            r'Ú†Ú©\s*(\d+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, str(description), re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def extract_currency_info(self, description):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø±Ø² Ø§Ø² Ø´Ø±Ø­"""
        if not description:
            return {'amount': None, 'currency': None, 'rate': None}
            
        patterns = [
            r'(\d[\d,\.]*)\s*(ÛŒÙˆØ±Ùˆ|Ø¯Ù„Ø§Ø±|ÛŒÙˆØ±Ùˆ|Ø±ÙŠØ§Ù„)\s*(?:Ù†Ø±Ø®|Ø¨Ø§ Ù†Ø±Ø®|ÙÙŠ|@)\s*(\d[\d,\.]*)',
            r'(\d[\d,\.]*)\s*(ÛŒÙˆØ±Ùˆ|Ø¯Ù„Ø§Ø±|ÛŒÙˆØ±Ùˆ)',
            r'(\d[\d,\.]*)\s*(EUR|USD|IRR)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, str(description))
            if match:
                amount_str = match.group(1).replace(',', '') if match.group(1) else None
                amount = float(amount_str) if amount_str else None
                currency = match.group(2)
                rate = match.group(3) if len(match.groups()) > 2 else None
                if rate:
                    rate = float(rate.replace(',', ''))
                
                return {
                    'amount': amount,
                    'currency': currency,
                    'rate': rate
                }
        
        return {'amount': None, 'currency': None, 'rate': None}
    
    def extract_company(self, description):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø´Ø±Ú©Øª Ø§Ø² Ø´Ø±Ø­"""
        if not description:
            return None
            
        companies = ['Ø§ÛŒØ±Ø§Ù†', 'Ø§ÛŒØ±Ø§ÛŒØªÚ©', 'Ù¾ØªØ±Ùˆ Ø³Ø§Ø­Ù„', 'ÙØ±Ø¢Ø¨', 'Ù†Ø§Ø±Ø¯ÛŒØ³', 'Ø®Ø§Ø±Ú©']
        for company in companies:
            if company in str(description):
                return company
        return None
    
    def detect_document_type(self, description):
        """ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³Ù†Ø¯"""
        if not description:
            return 'Ø³Ù†Ø¯ Ù…ØªÙØ±Ù‚Ù‡'
            
        desc_lower = str(description).lower()
        
        if 'ØªØ³Ø¹ÛŒØ±' in desc_lower or 'Ù†Ø±Ø®' in desc_lower:
            return 'ØªØ³Ø¹ÛŒØ± Ø§Ø±Ø²'
        elif 'ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª' in desc_lower or 'ØµÙˆØ±ØªÙˆØ¶Ø¹ÛŒØª' in desc_lower:
            return 'ØµÙˆØ±Øª ÙˆØ¶Ø¹ÛŒØª'
        elif 'Ú†Ú©' in desc_lower:
            return 'Ú†Ú©'
        elif 'Ø§Ù†ØªÙ‚Ø§Ù„' in desc_lower or 'Ù…Ø§Ù†Ø¯Ù‡' in desc_lower:
            return 'Ø§Ù†ØªÙ‚Ø§Ù„'
        else:
            return 'Ø³Ù†Ø¯ Ù…ØªÙØ±Ù‚Ù‡'
    
    def _convert_to_float(self, value):
        """Convert string value to float, handling commas and Persian numbers"""
        if value is None:
            return 0.0
        
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ùˆ Ø­Ø°Ù ÙØ§ØµÙ„Ù‡ Ùˆ Ú©Ø§Ù…Ø§
            value_str = str(value).strip()
            value_str = value_str.replace(',', '').replace(' ', '')
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
            persian_digits = 'Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹'
            english_digits = '0123456789'
            for p, e in zip(persian_digits, english_digits):
                value_str = value_str.replace(p, e)
            
            # Ø§Ú¯Ø± Ø±Ø´ØªÙ‡ Ø®Ø§Ù„ÛŒ Ø´Ø¯
            if not value_str:
                return 0.0
            
            return float(value_str)
        except (ValueError, TypeError):
            return 0.0
    
    def _process_excel_file(self, file_path, company_label):
        """Process Excel file and extract data"""
        try:
            # Read all sheets and combine
            excel_file = pd.ExcelFile(file_path)
            all_sheets_data = []
            
            for sheet_name in excel_file.sheet_names:
                df_sheet = pd.read_excel(file_path, sheet_name=sheet_name)
                df_sheet['sheet_name'] = sheet_name
                all_sheets_data.append(df_sheet)
            
            # Combine all sheets
            combined_df = pd.concat(all_sheets_data, ignore_index=True)
            
            # Standardize column names
            combined_df = self._standardize_columns(combined_df)
            
            print(f"âœ… ÙØ§ÛŒÙ„ {company_label} Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯: {len(combined_df)} Ø±Ú©ÙˆØ±Ø¯")
            return combined_df
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ {company_label}: {str(e)}")
            raise
    
    def _standardize_columns(self, df):
        """Standardize column names for Persian and English"""
        # Rename columns
        df.columns = [self.column_mapping.get(str(col).strip(), str(col).strip()) for col in df.columns]
        return df
    
    def _calculate_similarity(self, text1, text2):
        """Calculate text similarity using simple algorithm"""
        if not text1 or not text2:
            return 0.0
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©
        text1 = str(text1).lower()
        text2 = str(text2).lower()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ´Ø§Ø¨Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„Ù…Ø§Øª Ù…Ø´ØªØ±Ú©
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        common_words = words1.intersection(words2)
        similarity = len(common_words) / max(len(words1), len(words2)) * 100
        
        return similarity
    
    def _extract_smart_data(self, description_a, description_b):
        """Extract smart data from descriptions"""
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¬ÙˆØ¯
        invoice_number = self.extract_invoice_number(description_a) or self.extract_invoice_number(description_b)
        check_number = self.extract_check_number(description_a) or self.extract_check_number(description_b)
        currency_info = self.extract_currency_info(description_a) or self.extract_currency_info(description_b)
        company = self.extract_company(description_a) or self.extract_company(description_b)
        doc_type = self.detect_document_type(description_a) or self.detect_document_type(description_b)
        
        return {
            'invoice_number': invoice_number,
            'check_number': check_number,
            'currency': currency_info['currency'],
            'foreign_amount': currency_info['amount'],
            'exchange_rate': currency_info['rate'],
            'company_name': company,
            'document_type': doc_type,
        }
    
    def _find_exact_matches(self, df_a, df_b):
        """Find exact matches based on invoice number and amount"""
        matches = []
        
        for idx_a, row_a in df_a.iterrows():
            description_a = str(row_a.get('description', ''))
            amount_a = self._convert_to_float(row_a.get('amount', 0))
            invoice_number = self.extract_invoice_number(description_a)
            
            if invoice_number:
                # Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¯ÙˆÙ…
                for idx_b, row_b in df_b.iterrows():
                    description_b = str(row_b.get('description', ''))
                    amount_b = self._convert_to_float(row_b.get('amount', 0))
                    
                    if (self.extract_invoice_number(description_b) == invoice_number and 
                        abs(amount_a - amount_b) < 0.01):  # Ø§Ø®ØªÙ„Ø§Ù Ú©Ù…ØªØ± Ø§Ø² 0.01
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯
                        extracted_info = self._extract_smart_data(description_a, description_b)
                        
                        matches.append({
                            'statement_number': f"INV{invoice_number}",
                            'amount_a': amount_a,
                            'amount_b': amount_b,
                            'description_a': description_a,
                            'description_b': description_b,
                            'state': 'matched',
                            'similarity_score': 100.0,
                            'match_type': 'exact',
                            **extracted_info
                        })
                        break
        
        return matches
    
    def _find_fuzzy_matches(self, df_a, df_b):
        """Find fuzzy matches based on description similarity"""
        matches = []
        
        for idx_a, row_a in df_a.iterrows():
            description_a = str(row_a.get('description', ''))
            amount_a = self._convert_to_float(row_a.get('amount', 0))
            
            best_match = None
            best_score = 0
            
            for idx_b, row_b in df_b.iterrows():
                description_b = str(row_b.get('description', ''))
                amount_b = self._convert_to_float(row_b.get('amount', 0))
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ´Ø§Ø¨Ù‡ Ø´Ø±Ø­
                similarity = self._calculate_similarity(description_a, description_b)
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ´Ø§Ø¨Ù‡ Ù…Ø¨Ù„Øº (Ø§Ø®ØªÙ„Ø§Ù Ú©Ù…ØªØ± Ø§Ø² 1%)
                amount_similarity = 100.0 if abs(amount_a - amount_b) / max(amount_a, 1) < 0.01 else 0
                
                # Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ
                total_score = (similarity * 0.7) + (amount_similarity * 0.3)
                
                if total_score > best_score and total_score > 70:  # Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ´Ø§Ø¨Ù‡
                    best_score = total_score
                    best_match = (row_b, total_score)
            
            if best_match:
                row_b, score = best_match
                description_b = str(row_b.get('description', ''))
                amount_b = self._convert_to_float(row_b.get('amount', 0))
                
                extracted_info = self._extract_smart_data(description_a, description_b)
                
                matches.append({
                    'statement_number': f"FUZZY{idx_a}",
                    'amount_a': amount_a,
                    'amount_b': amount_b,
                    'description_a': description_a,
                    'description_b': description_b,
                    'state': 'matched',
                    'similarity_score': score,
                    'match_type': 'fuzzy',
                    **extracted_info
                })
        
        return matches
    
    def _find_missing_records(self, df_a, df_b, existing_matches):
        """Find records that exist in only one file"""
        missing_records = []
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø´Ø¯Ù‡
        matched_a_indices = set()
        matched_b_indices = set()
        
        for match in existing_matches:
            if match['description_a']:
                matched_a_indices.add(match['description_a'])
            if match['description_b']:
                matched_b_indices.add(match['description_b'])
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ Ø¯Ø± ÙØ§ÛŒÙ„ A
        for idx_b, row_b in df_b.iterrows():
            description_b = str(row_b.get('description', ''))
            if description_b and description_b not in matched_b_indices:
                amount_b = self._convert_to_float(row_b.get('amount', 0))
                
                extracted_info = self._extract_smart_data('', description_b)
                
                missing_records.append({
                    'statement_number': f"MISSING_A{idx_b}",
                    'amount_a': 0,
                    'amount_b': amount_b,
                    'description_a': '',
                    'description_b': description_b,
                    'state': 'missing_a',
                    'similarity_score': 0.0,
                    'match_type': 'none',
                    **extracted_info
                })
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ Ø¯Ø± ÙØ§ÛŒÙ„ B
        for idx_a, row_a in df_a.iterrows():
            description_a = str(row_a.get('description', ''))
            if description_a and description_a not in matched_a_indices:
                amount_a = self._convert_to_float(row_a.get('amount', 0))
                
                extracted_info = self._extract_smart_data(description_a, '')
                
                missing_records.append({
                    'statement_number': f"MISSING_B{idx_a}",
                    'amount_a': amount_a,
                    'amount_b': 0,
                    'description_a': description_a,
                    'description_b': '',
                    'state': 'missing_b',
                    'similarity_score': 0.0,
                    'match_type': 'none',
                    **extracted_info
                })
        
        return missing_records
    
    def run_reconciliation(self, file_a_path, file_b_path, output_path=None):
        """Run the complete reconciliation process"""
        print("ğŸš€ Ø´Ø±ÙˆØ¹ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯...")
        print("=" * 50)
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„
        df_a = self._process_excel_file(file_a_path, 'A')
        df_b = self._process_excel_file(file_b_path, 'B')
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚
        print("ğŸ” Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚...")
        
        # ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ - Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù…Ø§Ø±Ù‡ ØµÙˆØ±Øªâ€ŒÙˆØ¶Ø¹ÛŒØª Ùˆ Ù…Ø¨Ù„Øº
        exact_matches = self._find_exact_matches(df_a, df_b)
        print(f"   ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚: {len(exact_matches)} Ø±Ú©ÙˆØ±Ø¯")
        
        # ØªØ·Ø¨ÛŒÙ‚ ÙØ§Ø²ÛŒ - Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ´Ø§Ø¨Ù‡ Ø´Ø±Ø­ Ùˆ Ù…Ø¨Ù„Øº
        fuzzy_matches = self._find_fuzzy_matches(df_a, df_b)
        print(f"   ØªØ·Ø¨ÛŒÙ‚ ÙØ§Ø²ÛŒ: {len(fuzzy_matches)} Ø±Ú©ÙˆØ±Ø¯")
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯
        all_matches = exact_matches + fuzzy_matches
        missing_records = self._find_missing_records(df_a, df_b, all_matches)
        print(f"   Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯: {len(missing_records)} Ø±Ú©ÙˆØ±Ø¯")
        
        # ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… Ù†ØªØ§ÛŒØ¬
        analysis_lines = exact_matches + fuzzy_matches + missing_records
        
        # ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ù†ØªØ§ÛŒØ¬
        if output_path:
            self._generate_result_file(analysis_lines, output_path)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø®Ù„Ø§ØµÙ‡
        self._display_summary(analysis_lines)
        
        return analysis_lines
    
    def _generate_result_file(self, analysis_lines, output_path):
        """Generate result Excel file"""
        try:
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ù†ØªØ§ÛŒØ¬
            result_data = []
            for line in analysis_lines:
                result_data.append({
                    'Statement Number': line.get('statement_number', ''),
                    'Amount A': line.get('amount_a', 0),
                    'Amount B': line.get('amount_b', 0),
                    'Difference': line.get('amount_b', 0) - line.get('amount_a', 0),
                    'Status': line.get('state', ''),
                    'Similarity Score': line.get('similarity_score', 0),
                    'Match Type': line.get('match_type', ''),
                    'Invoice Number': line.get('invoice_number', ''),
                    'Check Number': line.get('check_number', ''),
                    'Company': line.get('company_name', ''),
                    'Document Type': line.get('document_type', ''),
                    'Description A': line.get('description_a', ''),
                    'Description B': line.get('description_b', ''),
                })
            
            result_df = pd.DataFrame(result_data)
            
            # Ø¢Ù…Ø§Ø± Ø®Ù„Ø§ØµÙ‡
            summary_data = {
                'Metric': ['Total Records', 'Matched Records', 'Mismatch Records', 'Missing in A', 'Missing in B'],
                'Count': [
                    len(analysis_lines),
                    len([l for l in analysis_lines if l['state'] == 'matched']),
                    len([l for l in analysis_lines if l['state'] == 'mismatch']),
                    len([l for l in analysis_lines if l['state'] == 'missing_a']),
                    len([l for l in analysis_lines if l['state'] == 'missing_b']),
                ]
            }
            summary_df = pd.DataFrame(summary_data)
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                result_df.to_excel(writer, sheet_name='Reconciliation Results', index=False)
                summary_df.to_excel(writer, sheet_name='Summary', index=False)
            
            print(f"âœ… ÙØ§ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {output_path}")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ ÙØ§ÛŒÙ„ Ù†ØªØ§ÛŒØ¬: {str(e)}")
            raise
    
    def _display_summary(self, analysis_lines):
        """Display summary statistics"""
        print("\nğŸ“Š Ø¢Ù…Ø§Ø± Ø®Ù„Ø§ØµÙ‡ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ:")
        print("=" * 40)
        print(f"   Ú©Ù„ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {len(analysis_lines)}")
        print(f"   Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªØ·Ø¨ÛŒÙ‚ Ø´Ø¯Ù‡: {len([l for l in analysis_lines if l['state'] == 'matched'])}")
        print(f"   Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ù…ØºØ§ÛŒØ±Øª: {len([l for l in analysis_lines if l['state'] == 'mismatch'])}")
        print(f"   Ù…ÙÙ‚ÙˆØ¯ Ø¯Ø± ÙØ§ÛŒÙ„ A: {len([l for l in analysis_lines if l['state'] == 'missing_a'])}")
        print(f"   Ù…ÙÙ‚ÙˆØ¯ Ø¯Ø± ÙØ§ÛŒÙ„ B: {len([l for l in analysis_lines if l['state'] == 'missing_b'])}")
        print("=" * 40)


def main():
    """Main function for command line usage"""
    parser = argparse.ArgumentParser(description='Ø³ÛŒØ³ØªÙ… Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø³ØªÙ‚Ù„')
    parser.add_argument('file_a', help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø´Ø±Ú©Øª A')
    parser.add_argument('file_b', help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø´Ø±Ú©Øª B')
    parser.add_argument('-o', '--output', help='Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)', default='reconciliation_results.xlsx')
    
    args = parser.parse_args()
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    if not os.path.exists(args.file_a):
        print(f"âŒ ÙØ§ÛŒÙ„ {args.file_a} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return
    
    if not os.path.exists(args.file_b):
        print(f"âŒ ÙØ§ÛŒÙ„ {args.file_b} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ
    reconciliation = StandaloneReconciliation()
    try:
        results = reconciliation.run_reconciliation(args.file_a, args.file_b, args.output)
        print(f"\nğŸ‰ Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
        print(f"ğŸ“ ÙØ§ÛŒÙ„ Ù†ØªØ§ÛŒØ¬: {args.output}")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù…ØºØ§ÛŒØ±Øªâ€ŒÚ¯ÛŒØ±ÛŒ: {str(e)}")


if __name__ == "__main__":
    main()
